// Package pgregress provides tools for running PostgreSQL regression test
// SQL files against the pgparser parser to verify parse compatibility.
package pgregress

import (
	"bytes"
	"regexp"
	"strings"
	"unicode"
)

// ExtractedStmt represents a single SQL statement extracted from a .sql file.
type ExtractedStmt struct {
	SQL       string // The complete SQL text (without trailing semicolon)
	File      string // Source filename (basename)
	StartLine int    // 1-based line number where this statement starts
}

// ExtractStatements splits a PostgreSQL regression test .sql file into
// individual SQL statements. It handles psql metacommands, dollar-quoted
// strings, COPY FROM stdin data blocks, and all PostgreSQL string literal forms.
func ExtractStatements(filename string, content []byte) []ExtractedStmt {
	lines := preprocessLines(content)
	return splitStatements(filename, lines)
}

// processedLine is a line after psql metacommand preprocessing.
type processedLine struct {
	text       string // SQL text for this line (empty if skipped)
	lineNum    int    // original 1-based line number
	terminates bool   // true if a psql terminator (\g, \gset, \gx) ended this line
}

// psqlTerminatorRE matches psql metacommands that act as statement terminators.
var psqlTerminatorRE = regexp.MustCompile(`(?i)\\(g|gx|gset)\b`)

// copyFromStdinRE detects COPY ... FROM STDIN statements.
var copyFromStdinRE = regexp.MustCompile(`(?i)\bCOPY\b[^;]*\bFROM\b\s+STDIN\b`)

// preprocessLines handles psql metacommands and COPY FROM stdin data blocks.
// It returns processed lines with metacommands removed and COPY data skipped.
func preprocessLines(content []byte) []processedLine {
	rawLines := bytes.Split(content, []byte("\n"))
	result := make([]processedLine, 0, len(rawLines))
	inCopyData := false

	for i, raw := range rawLines {
		lineNum := i + 1
		line := string(raw)

		// In COPY data mode, skip until \. terminator
		if inCopyData {
			trimmed := strings.TrimRight(line, "\r")
			if trimmed == "\\." {
				inCopyData = false
			}
			// Skip this line either way (data or terminator)
			result = append(result, processedLine{lineNum: lineNum})
			continue
		}

		trimmedLeft := strings.TrimLeftFunc(line, unicode.IsSpace)

		// Check for psql metacommand (line starts with \)
		if strings.HasPrefix(trimmedLeft, `\`) {
			pl := processedLine{lineNum: lineNum}
			// If this is a terminator like \g, \gset, \gx, mark it
			if psqlTerminatorRE.MatchString(trimmedLeft) {
				pl.terminates = true
			}
			result = append(result, pl)
			continue
		}

		// Check for mid-line psql metacommand (e.g., "SELECT 1 \gset")
		// We need to find \ that starts a metacommand but is NOT inside a string.
		sqlPart, terminated := splitMidLineMeta(line)
		if terminated {
			result = append(result, processedLine{
				text:       sqlPart,
				lineNum:    lineNum,
				terminates: true,
			})
			continue
		}

		// Normal SQL line
		result = append(result, processedLine{
			text:    line,
			lineNum: lineNum,
		})

		// Check if this line completes a COPY FROM STDIN statement.
		// We check if the line ends with a semicolon (possibly after whitespace)
		// and the accumulated context looks like COPY FROM STDIN.
		// This is a heuristic: we'll do the real check in splitStatements
		// after we see the full statement. But for the line-level preprocessing,
		// we set inCopyData after the statement-ending semicolon on a COPY FROM STDIN.
		// Actually, the real detection must happen at the statement level.
		// We'll handle this by scanning for the pattern across the recent lines.
		// For simplicity, check if this line contains "stdin" + ";" pattern.
		if looksLikeCopyStdinEnd(line) {
			inCopyData = true
		}
	}

	return result
}

// looksLikeCopyStdinEnd is a quick heuristic to detect if a line might end
// a COPY FROM STDIN statement. We look for STDIN followed by optional clauses and ;.
// This is imperfect but sufficient for regression test files.
func looksLikeCopyStdinEnd(line string) bool {
	upper := strings.ToUpper(line)
	// Check this single line for the pattern
	if strings.Contains(upper, "STDIN") && strings.Contains(line, ";") {
		return true
	}
	return false
}

// splitMidLineMeta checks if a line contains a mid-line psql metacommand
// like "SELECT 1 \gset". Returns the SQL portion and whether it terminated.
// It does a simple scan to avoid splitting inside strings.
func splitMidLineMeta(line string) (sqlPart string, terminated bool) {
	n := len(line)
	inSingle := false
	inDouble := false
	inDollar := false
	dollarTag := ""
	i := 0

	for i < n {
		ch := line[i]

		if inSingle {
			if ch == '\'' {
				if i+1 < n && line[i+1] == '\'' {
					i += 2
					continue
				}
				inSingle = false
			}
			i++
			continue
		}

		if inDouble {
			if ch == '"' {
				if i+1 < n && line[i+1] == '"' {
					i += 2
					continue
				}
				inDouble = false
			}
			i++
			continue
		}

		if inDollar {
			// Look for closing dollar tag
			if ch == '$' && i+len(dollarTag) <= n && line[i:i+len(dollarTag)] == dollarTag {
				i += len(dollarTag)
				inDollar = false
				continue
			}
			i++
			continue
		}

		switch ch {
		case '\'':
			// Check for E'...'
			if i > 0 && (line[i-1] == 'E' || line[i-1] == 'e') {
				// E-string, still enters single-quote mode
			}
			inSingle = true
			i++
		case '"':
			inDouble = true
			i++
		case '$':
			tag := tryParseDollarTagStr(line, i)
			if tag != "" {
				dollarTag = tag
				inDollar = true
				i += len(tag)
			} else {
				i++
			}
		case '-':
			if i+1 < n && line[i+1] == '-' {
				// Line comment - rest of line is comment, no metacommand possible
				return "", false
			}
			i++
		case '\\':
			// Potential psql metacommand
			rest := line[i:]
			if psqlTerminatorRE.MatchString(rest) {
				return strings.TrimRight(line[:i], " \t"), true
			}
			// Other backslash mid-line (e.g., \echo) - also treat as terminator
			// for the SQL portion if there's SQL before it
			if i > 0 && strings.TrimSpace(line[:i]) != "" {
				// Check if it looks like a psql command
				if len(rest) > 1 && (rest[1] >= 'a' && rest[1] <= 'z' || rest[1] >= 'A' && rest[1] <= 'Z') {
					return strings.TrimRight(line[:i], " \t"), false
				}
			}
			i++
		default:
			i++
		}
	}

	return "", false
}

// extractState represents the scanner state for statement splitting.
type extractState int

const (
	stNormal       extractState = iota
	stSingleQuote               // inside '...'
	stEscapeString              // inside E'...' with backslash escapes
	stDoubleQuote               // inside "..."
	stDollarQuote               // inside $$...$$ or $tag$...$tag$
	stBlockComment              // inside /* ... */
)

// splitStatements takes preprocessed lines and splits them into SQL statements
// by scanning for semicolons outside of strings, comments, and dollar-quoted blocks.
func splitStatements(filename string, lines []processedLine) []ExtractedStmt {
	var result []ExtractedStmt
	var buf strings.Builder
	state := stNormal
	blockDepth := 0
	dollarTag := ""
	stmtStartLine := 0
	hasContent := false // true if buf has non-whitespace content
	hasSQL := false     // true if buf has non-comment SQL content
	inCopyData := false

	emit := func() {
		sql := strings.TrimSpace(buf.String())
		if sql != "" && hasSQL {
			result = append(result, ExtractedStmt{
				SQL:       sql,
				File:      filename,
				StartLine: stmtStartLine,
			})
			// Check if this was COPY FROM STDIN
			if copyFromStdinRE.MatchString(sql) {
				inCopyData = true
			}
		}
		buf.Reset()
		hasContent = false
		hasSQL = false
		stmtStartLine = 0
	}

	for _, pl := range lines {
		// Skip empty preprocessed lines (metacommands, copy data)
		if pl.text == "" {
			if inCopyData {
				// The preprocessor already handled \. detection,
				// but we need to know when copy data ends.
				// Check the raw state: if preprocessor set text="" for
				// a non-copy-data reason, we need to keep inCopyData.
				// Actually preprocessor handles inCopyData separately.
				// Let's just check: if we are in copy data and see
				// the terminator signal (next non-empty line), we exit.
				// Simpler: preprocessor already skipped copy data.
				// We just need to reset inCopyData when we get a non-empty line.
				continue
			}
			if pl.terminates {
				// Metacommand that terminates a statement (e.g., \gset on its own line)
				emit()
			}
			continue
		}

		// We got a non-empty line, so COPY data mode is over
		if inCopyData {
			inCopyData = false
		}

		text := pl.text
		n := len(text)

		for i := 0; i < n; i++ {
			ch := text[i]

			// Track statement start line
			if !hasContent && !isSpaceByte(ch) {
				stmtStartLine = pl.lineNum
				hasContent = true
			}

			switch state {
			case stNormal:
				switch {
				case ch == ';':
					// Statement terminator
					emit()

				case ch == '-' && i+1 < n && text[i+1] == '-':
					// Line comment: include rest of line in buffer
					buf.WriteString(text[i:])
					i = n // skip rest of line
					// Note: do NOT set hasSQL — comments alone don't make a statement

				case ch == '/' && i+1 < n && text[i+1] == '*':
					// Block comment start
					state = stBlockComment
					blockDepth = 1
					buf.WriteString("/*")
					i++ // skip *
					// Note: do NOT set hasSQL — block comments alone don't make a statement

				case ch == '\'' && i > 0 && (text[i-1] == 'E' || text[i-1] == 'e'):
					// E-string (the E was already written to buf)
					state = stEscapeString
					hasSQL = true
					buf.WriteByte(ch)

				case ch == '\'':
					state = stSingleQuote
					hasSQL = true
					buf.WriteByte(ch)

				case ch == '"':
					state = stDoubleQuote
					hasSQL = true
					buf.WriteByte(ch)

				case ch == '$':
					tag := tryParseDollarTagStr(text, i)
					if tag != "" {
						dollarTag = tag
						state = stDollarQuote
						hasSQL = true
						buf.WriteString(tag)
						i += len(tag) - 1 // -1 because loop increments
					} else {
						hasSQL = true
						buf.WriteByte(ch)
					}

				case ch == '\\' && i+1 < n && text[i+1] == ';':
					// psql \; separator: emit current statement and skip the \;
					emit()
					i++ // skip the ; as well

				default:
					if !isSpaceByte(ch) {
						hasSQL = true
					}
					buf.WriteByte(ch)
				}

			case stSingleQuote:
				buf.WriteByte(ch)
				if ch == '\'' {
					if i+1 < n && text[i+1] == '\'' {
						// Escaped quote ''
						buf.WriteByte('\'')
						i++
					} else {
						state = stNormal
					}
				}

			case stEscapeString:
				buf.WriteByte(ch)
				if ch == '\\' {
					// Backslash escape: consume next char
					if i+1 < n {
						i++
						buf.WriteByte(text[i])
					}
				} else if ch == '\'' {
					if i+1 < n && text[i+1] == '\'' {
						buf.WriteByte('\'')
						i++
					} else {
						state = stNormal
					}
				}

			case stDoubleQuote:
				buf.WriteByte(ch)
				if ch == '"' {
					if i+1 < n && text[i+1] == '"' {
						buf.WriteByte('"')
						i++
					} else {
						state = stNormal
					}
				}

			case stDollarQuote:
				if ch == '$' && i+len(dollarTag) <= n && text[i:i+len(dollarTag)] == dollarTag {
					buf.WriteString(dollarTag)
					i += len(dollarTag) - 1
					state = stNormal
				} else {
					buf.WriteByte(ch)
				}

			case stBlockComment:
				if ch == '/' && i+1 < n && text[i+1] == '*' {
					blockDepth++
					buf.WriteString("/*")
					i++
				} else if ch == '*' && i+1 < n && text[i+1] == '/' {
					blockDepth--
					buf.WriteString("*/")
					i++
					if blockDepth == 0 {
						state = stNormal
					}
				} else {
					buf.WriteByte(ch)
				}
			}
		}

		// End of line: add newline to buffer if we have content
		// (preserves multi-line statement formatting)
		if hasContent || buf.Len() > 0 {
			buf.WriteByte('\n')
		}

		// Check for psql terminator on this line
		if pl.terminates && state == stNormal {
			emit()
		}
	}

	// Emit any remaining statement
	emit()

	return result
}

// tryParseDollarTagStr tries to parse a dollar-quote tag at position i in s.
// Returns the full tag (e.g., "$$" or "$body$") or "" if not a valid dollar tag.
func tryParseDollarTagStr(s string, i int) string {
	if i >= len(s) || s[i] != '$' {
		return ""
	}

	// Try to match $[tag]$ where tag is [a-zA-Z_][a-zA-Z0-9_]*
	j := i + 1

	// Empty tag: $$
	if j < len(s) && s[j] == '$' {
		return "$$"
	}

	// Tag must start with letter or underscore
	if j >= len(s) {
		return ""
	}
	if !isIdentStart(s[j]) {
		return ""
	}

	// Consume identifier characters
	j++
	for j < len(s) && isIdentCont(s[j]) {
		j++
	}

	// Must end with $
	if j >= len(s) || s[j] != '$' {
		return ""
	}

	return s[i : j+1]
}

func isIdentStart(c byte) bool {
	return (c >= 'a' && c <= 'z') || (c >= 'A' && c <= 'Z') || c == '_'
}

func isIdentCont(c byte) bool {
	return isIdentStart(c) || (c >= '0' && c <= '9')
}

func isSpaceByte(c byte) bool {
	return c == ' ' || c == '\t' || c == '\n' || c == '\r'
}
